                 from  n    params  module                                  arguments
  0                -1  1      5280  models.common.Focus                     [3, 48, 3]
  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]
  2                -1  1     65280  models.common.C3                        [96, 96, 2]
  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]
  4                -1  1    629760  models.common.C3                        [192, 192, 6]
  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]
  6                -1  1   2512896  models.common.C3                        [384, 384, 6]
  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]
  8                -1  1   1476864  models.common.SPP                       [768, 768, [5, 9, 13]]
  9                -1  1   4134912  models.common.C3                        [768, 768, 2, False]
 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 6]  1         0  models.common.Concat                    [1]
 13                -1  1   1182720  models.common.C3                        [768, 384, 2, False]
 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 16           [-1, 4]  1         0  models.common.Concat                    [1]
 17                -1  1    296448  models.common.C3                        [384, 192, 2, False]
 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]
 19          [-1, 14]  1         0  models.common.Concat                    [1]
 20                -1  1   1035264  models.common.C3                        [384, 384, 2, False]
 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]
 22          [-1, 10]  1         0  models.common.Concat                    [1]
 23                -1  1   4134912  models.common.C3                        [768, 768, 2, False]
 24      [17, 20, 23]  1     28287  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]
Model Summary: 391 layers, 21060447 parameters, 21060447 gradients, 50.4 GFLOPs
Transferred 498/506 items from yolov5m.pt
Scaled weight_decay = 0.0005
Optimizer groups: 86 .bias, 86 conv.weight, 83 other
[34m[1mtrain: [39m[22mScanning '/var/dataSSD/person_head_detector/train.cache' images and labels... 22026 found, 0 missing, 0 empty, 162 corrupted: 100% 22026/22026 [00:00<?, ?it/s]
Plotting labels...
[34m[1mval: [39m[22mScanning '/var/dataSSD/person_head_detector/val.cache' images and labels... 750 found, 0 missing, 0 empty, 3 corrupted: 100% 750/750 [00:00<?, ?it/s]
[34m[1mautoanchor: [39m[22mAnalyzing anchors... anchors/target = 4.03, Best Possible Recall (BPR) = 0.9619. Attempting to improve anchors, please wait...
[34m[1mautoanchor: [39m[22mWARNING: Extremely small objects found. 32425 of 818884 labels are < 3 pixels in size.
[34m[1mautoanchor: [39m[22mRunning kmeans for 9 anchors on 811158 points...
[34m[1mautoanchor: [39m[22mthr=0.25: 0.9902 best possible recall, 3.86 anchors past thr
[34m[1mautoanchor: [39m[22mn=9, img_size=640, metric_all=0.273/0.715-mean/best, past_thr=0.497-mean: 6,8,  14,21,  23,40,  39,61,  42,123,  85,112,  77,217,  149,307,  325,406












































[34m[1mautoanchor: [39m[22mEvolving anchors with Genetic Algorithm: fitness = 0.7504: 100% 997/1000 [01:29<00:00, 13.81it/s]
[34m[1mautoanchor: [39m[22mthr=0.25: 0.9953 best possible recall, 4.11 anchors past thr
[34m[1mautoanchor: [39m[22mn=9, img_size=640, metric_all=0.289/0.746-mean/best, past_thr=0.504-mean: 5,6,  10,12,  17,23,  27,36,  30,82,  66,80,  58,175,  112,253,  332,454
[34m[1mautoanchor: [39m[22mEvolving anchors with Genetic Algorithm: fitness = 0.7504: 100% 1000/1000 [01:29<00:00, 11.13it/s]
Image sizes 640 train, 640 test
Using 8 dataloader workers
Logging results to runs/train/exp7
Starting training for 300 epochs...
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size


